## K8S 部署

```shell

# 所有主机：基本系统配置

# 关闭Selinux/firewalld
systemctl stop firewalld
systemctl disable firewalld
setenforce 0

# 关闭交换分区
sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config
swapoff -a
yes | cp /etc/fstab /etc/fstab_bak
cat /etc/fstab_bak |grep -v swap > /etc/fstab

# 设置网桥包经IPTables，core文件生成路径
echo """
vm.swappiness = 0
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
""" > /etc/sysctl.conf
sysctl -p

# 同步时间
yum install -y ntpdate
ntpdate -u ntp.api.bz

# 安装内核组件
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm ;yum --enablerepo=elrepo-kernel install kernel-lt-devel kernel-lt -y

# 检查默认内核版本高于4.1，否则请调整默认启动参数
grub2-editenv list

#重启以更换内核
reboot

# 确认内核版本
uname -a

# 确认内核高于4.1后，开启IPVS
cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"

for kernel_module in \${ipvs_modules}; do
/sbin/modinfo -F filename \${kernel_module} > /dev/null 2>&1
 
if [ $? -eq 0 ];then
/sbin/modprobe \${kernel_module} 
fi
done
EOF

chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep ip_vs


# 所有主机：安装配置docker

#yum install -y yum-utils device-mapper-persistent-data lvm2
#yum-config-manager \
# --add-repo \
# https://download.docker.com/linux/centos/docker-ce.repo
#
#yum makecache fast
#yum install -y docker-ce

sudo yum install -y yum-utils device-mapper-persistent-data lvm2
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
sudo yum makecache fast
sudo yum -y install docker-ce

# 编辑systemctl的Docker启动文件
sed -i "13i ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT" /usr/lib/systemd/system/docker.service

# 启动docker
systemctl daemon-reload
systemctl enable docker
systemctl start docker

# 为Docker配置一下私有源
mkdir -p /etc/docker
echo -e '{\n"insecure-registries":["k8s.gcr.io", "gcr.io", "quay.io"]\n}' > /etc/docker/daemon.json 
systemctl restart docker

# 此处应当修改为harbor所在机器的IP
HARBOR_HOST="192.168.1.205"

# 设置Hosts
yes | cp /etc/hosts /etc/hosts_bak

cat /etc/hosts_bak|grep -vE '(gcr.io|harbor.io|quay.io)' > /etc/hosts
echo """
$HARBOR_HOST gcr.io harbor.io k8s.gcr.io quay.io """ >> /etc/hosts

```



Kubernetes要求集群中所有机器具有不同的Mac地址、产品uuid、Hostname。可以使用如下命令查看Mac和uuid 

```shell
cat /sys/class/dmi/id/product_uuid
ip link
```



### 安装配置Docker

```shell
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
  
yum makecache fast
yum install -y docker-ce
 
# 编辑systemctl的Docker启动文件
sed -i "13i ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT" /usr/lib/systemd/system/docker.service
 
# 启动docker
systemctl daemon-reload
systemctl enable docker
systemctl start docker
```



### 安装私有镜像库

```shell
yum install -y yum-utils device-mapper-persistent-data lvm2
yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
  
yum makecache fast
yum install -y docker-ce
 
# 编辑systemctl的Docker启动文件
sed -i "13i ExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPT" /usr/lib/systemd/system/docker.service
 
# 启动docker
systemctl daemon-reload
systemctl enable docker
systemctl start docker
```



### 安装私有镜像库

```shell
# 为Docker配置一下私有源
mkdir -p /etc/docker
echo -e '{\n"insecure-registries":["k8s.gcr.io", "gcr.io", "quay.io"]\n}' > /etc/docker/daemon.json
systemctl restart docker
 
# 此处应当修改为harbor所在机器的IP
HARBOR_HOST="10.130.38.80"
# 设置Hosts
yes | cp /etc/hosts /etc/hosts_bak
cat /etc/hosts_bak|grep -vE '(gcr.io|harbor.io|quay.io)' > /etc/hosts
echo """
$HARBOR_HOST gcr.io
$HARBOR_HOST harbor.io
$HARBOR_HOST k8s.gcr.io
$HARBOR_HOST quay.io """ >> /etc/hosts
```



下载链接：https://pan.baidu.com/s/17PV_VRYIbfmPz1qiiR_yGg 密码：newp，随后将该文件放置到harbor机器上，并在harbor主机上加载、启动该镜像 

```shell
docker load -i /path/to/k8s-repo-1.11.0
docker run --restart=always -d -p 80:5000 --name repo harbor.io:1180/system/k8s-repo:v1.11.0
```



### 安装配置kubernetes

首先下载链接：https://pan.baidu.com/s/1tOIFgnexs25XWHxitLmmVQ 密码：lqth，并放置在k8s各个master和worker主机上 

```
yum install -y socat keepalived ipvsadm
cd /path/to/downloaded/file
tar -xzvf k8s-v1.11.0-rpms.tgz
cd k8s-v1.11.0
rpm -ivh *
systemctl enable kubelet
kubeadm version -o short
```



#### 配置免密码登陆

```shell
ssh-keygen
# 三次回车后，密钥生成完成
cat ~/.ssh/id_rsa.pub
# 得到该机器的公钥如下图
```

将该公钥复制，并分别登陆到master-1 master-2 master-3的root用户，将它令起一行粘贴到 ~/.ssh/authorized_keys 文件中，**包括master-1自己**

复制完成后，**从master-1上分别登陆master-1 master-2 master-3测试是否可以免密码登陆(请不要跳过这一步)**，可以的话便可以继续执行下一步



#### 部署HA Master

HA Master的部署过程已经自动化，请在master-1上执行如下命令，并注意修改IP和Hostname 

```shell
# 创建集群信息文件
echo """
CP0_IP=10.130.29.80
CP0_HOSTNAME=centos-7-x86-64-29-80
CP1_IP=10.130.29.81
CP1_HOSTNAME=centos-7-x86-64-29-81
CP2_IP=10.130.29.82
CP2_HOSTNAME=centos-7-x86-64-29-82
VIP=10.130.29.83
NET_IF=eth0
CIDR=172.168.0.0/16
""" > ./cluster-info
 
bash -c "$(curl -fsSL https://raw.githubusercontent.com/Lentil1016/kubeadm-ha/1.11.0/kubeha-gen.sh)"
# 该步骤将可能持续2到10分钟，在该脚本进行安装部署前，将有一次对安装信息进行检查确认的机会
```

可以在[该链接](https://asciinema.org/a/BEGzoZYwRZESD1td128rhlgSH)查看安装全过程的录像，安装结束后会打印出如下的信息，最后一行为加入集群的命令，其中加入集群的IP已经被更换为了高可用的VIP 



#### 加入work node

现在可以将各节点入编到集群中。join command是由kubeadm动态生成的，其基本形式如下 

```
kubeadm join --token fae76b.88ae6b2ad052b67f 10.130.29.83:6443 --discovery-token-ca-cert-hash sha256:9ed673962fd437dc556ccab07d02d718da01cf5db1b6eeaf443ecadd891a73e8
```

随后到worker节点执行刚刚生成的join command即可将该节点编入集群。 

```
kubeadm join --token fae76b.88ae6b2ad052b67f 10.130.29.83:6443 --discovery-token-ca-cert-hash sha256:9ed673962fd437dc556ccab07d02d718da01cf5db1b6eeaf443ecadd891a73e8
```



转自：https://lentil1016.cn/kubeadm-ha%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97/
